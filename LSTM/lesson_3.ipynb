{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73b0fbe4",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20971cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  \n",
    "from collections import Counter\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6066d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = \"\"\"Bu ürün beklentimi fazlasyıla karşıladı.\n",
    "Malzeme kalitesi gerçekten çok iyi.\n",
    "Kargo hızlı ve sorunsuz bi şekilde elime ulaştı.\n",
    "Fiyatına göre performansı harika.\n",
    "Kesinlikle tavsiye ve ederim!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dbb44a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = texts.replace(\".\", \"\").replace(\"!\", \"\").lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "168bd045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bu',\n",
       " 'ürün',\n",
       " 'beklentimi',\n",
       " 'fazlasyıla',\n",
       " 'karşıladı',\n",
       " 'malzeme',\n",
       " 'kalitesi',\n",
       " 'gerçekten',\n",
       " 'çok',\n",
       " 'iyi',\n",
       " 'kargo',\n",
       " 'hızlı',\n",
       " 've',\n",
       " 'sorunsuz',\n",
       " 'bi',\n",
       " 'şekilde',\n",
       " 'elime',\n",
       " 'ulaştı',\n",
       " 'fiyatına',\n",
       " 'göre',\n",
       " 'performansı',\n",
       " 'harika',\n",
       " 'kesinlikle',\n",
       " 'tavsiye',\n",
       " 've',\n",
       " 'ederim']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ce0e5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ve': 2,\n",
       "         'bu': 1,\n",
       "         'ürün': 1,\n",
       "         'beklentimi': 1,\n",
       "         'fazlasyıla': 1,\n",
       "         'karşıladı': 1,\n",
       "         'malzeme': 1,\n",
       "         'kalitesi': 1,\n",
       "         'gerçekten': 1,\n",
       "         'çok': 1,\n",
       "         'iyi': 1,\n",
       "         'kargo': 1,\n",
       "         'hızlı': 1,\n",
       "         'sorunsuz': 1,\n",
       "         'bi': 1,\n",
       "         'şekilde': 1,\n",
       "         'elime': 1,\n",
       "         'ulaştı': 1,\n",
       "         'fiyatına': 1,\n",
       "         'göre': 1,\n",
       "         'performansı': 1,\n",
       "         'harika': 1,\n",
       "         'kesinlikle': 1,\n",
       "         'tavsiye': 1,\n",
       "         'ederim': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = Counter(words)\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be6ed2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ve',\n",
       " 'bu',\n",
       " 'ürün',\n",
       " 'beklentimi',\n",
       " 'fazlasyıla',\n",
       " 'karşıladı',\n",
       " 'malzeme',\n",
       " 'kalitesi',\n",
       " 'gerçekten',\n",
       " 'çok',\n",
       " 'iyi',\n",
       " 'kargo',\n",
       " 'hızlı',\n",
       " 'sorunsuz',\n",
       " 'bi',\n",
       " 'şekilde',\n",
       " 'elime',\n",
       " 'ulaştı',\n",
       " 'fiyatına',\n",
       " 'göre',\n",
       " 'performansı',\n",
       " 'harika',\n",
       " 'kesinlikle',\n",
       " 'tavsiye',\n",
       " 'ederim']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5007751c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ve': 0,\n",
       " 'bu': 1,\n",
       " 'ürün': 2,\n",
       " 'beklentimi': 3,\n",
       " 'fazlasyıla': 4,\n",
       " 'karşıladı': 5,\n",
       " 'malzeme': 6,\n",
       " 'kalitesi': 7,\n",
       " 'gerçekten': 8,\n",
       " 'çok': 9,\n",
       " 'iyi': 10,\n",
       " 'kargo': 11,\n",
       " 'hızlı': 12,\n",
       " 'sorunsuz': 13,\n",
       " 'bi': 14,\n",
       " 'şekilde': 15,\n",
       " 'elime': 16,\n",
       " 'ulaştı': 17,\n",
       " 'fiyatına': 18,\n",
       " 'göre': 19,\n",
       " 'performansı': 20,\n",
       " 'harika': 21,\n",
       " 'kesinlikle': 22,\n",
       " 'tavsiye': 23,\n",
       " 'ederim': 24}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ccdbc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 've',\n",
       " 1: 'bu',\n",
       " 2: 'ürün',\n",
       " 3: 'beklentimi',\n",
       " 4: 'fazlasyıla',\n",
       " 5: 'karşıladı',\n",
       " 6: 'malzeme',\n",
       " 7: 'kalitesi',\n",
       " 8: 'gerçekten',\n",
       " 9: 'çok',\n",
       " 10: 'iyi',\n",
       " 11: 'kargo',\n",
       " 12: 'hızlı',\n",
       " 13: 'sorunsuz',\n",
       " 14: 'bi',\n",
       " 15: 'şekilde',\n",
       " 16: 'elime',\n",
       " 17: 'ulaştı',\n",
       " 18: 'fiyatına',\n",
       " 19: 'göre',\n",
       " 20: 'performansı',\n",
       " 21: 'harika',\n",
       " 22: 'kesinlikle',\n",
       " 23: 'tavsiye',\n",
       " 24: 'ederim'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_vocab = {i: word for i, word in enumerate(vocab)}\n",
    "index_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0970a01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bu', 'ürün'),\n",
       " ('ürün', 'beklentimi'),\n",
       " ('beklentimi', 'fazlasyıla'),\n",
       " ('fazlasyıla', 'karşıladı'),\n",
       " ('karşıladı', 'malzeme'),\n",
       " ('malzeme', 'kalitesi'),\n",
       " ('kalitesi', 'gerçekten'),\n",
       " ('gerçekten', 'çok'),\n",
       " ('çok', 'iyi'),\n",
       " ('iyi', 'kargo'),\n",
       " ('kargo', 'hızlı'),\n",
       " ('hızlı', 've'),\n",
       " ('ve', 'sorunsuz'),\n",
       " ('sorunsuz', 'bi'),\n",
       " ('bi', 'şekilde'),\n",
       " ('şekilde', 'elime'),\n",
       " ('elime', 'ulaştı'),\n",
       " ('ulaştı', 'fiyatına'),\n",
       " ('fiyatına', 'göre'),\n",
       " ('göre', 'performansı'),\n",
       " ('performansı', 'harika'),\n",
       " ('harika', 'kesinlikle'),\n",
       " ('kesinlikle', 'tavsiye'),\n",
       " ('tavsiye', 've'),\n",
       " ('ve', 'ederim')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(words[i], words[i+1]) for i in range(len(words)-1)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "402a4c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embedding): Embedding(25, 1)\n",
       "  (lstm): LSTM(1, 1)\n",
       "  (fc): Linear(in_features=1, out_features=25, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size)\n",
    "        self.fc = nn.Linear(in_features=hidden_size, out_features=vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x.view(1, 1, -1))\n",
    "        x = self.fc(x.view(1, -1))\n",
    "        return x\n",
    "    \n",
    "model = LSTM(vocab_size=len(vocab), embedding_dim=1, hidden_size=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95318c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_squence(seq, to_idx):\n",
    "    return torch.tensor([to_idx[w] for w in seq], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88211dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning basliyor\n",
      "Embedding dim: 8, Hidden S: 32, Learning Rate: 0.001\n",
      "Epoch: 1, Loss: 80.63410\n",
      "Epoch: 2, Loss: 79.95472\n",
      "Epoch: 3, Loss: 79.47386\n",
      "Epoch: 4, Loss: 78.97199\n",
      "Epoch: 5, Loss: 78.43119\n",
      "Epoch: 6, Loss: 77.83633\n",
      "Epoch: 7, Loss: 77.17184\n",
      "Epoch: 8, Loss: 76.42155\n",
      "Epoch: 9, Loss: 75.56917\n",
      "Epoch: 10, Loss: 74.59889\n",
      "Epoch: 11, Loss: 73.49631\n",
      "Epoch: 12, Loss: 72.24942\n",
      "Epoch: 13, Loss: 70.84957\n",
      "Epoch: 14, Loss: 69.29217\n",
      "Epoch: 15, Loss: 67.57738\n",
      "Epoch: 16, Loss: 65.71045\n",
      "Epoch: 17, Loss: 63.70177\n",
      "Epoch: 18, Loss: 61.56672\n",
      "Epoch: 19, Loss: 59.32499\n",
      "Epoch: 20, Loss: 56.99963\n",
      "Epoch: 21, Loss: 54.61563\n",
      "Epoch: 22, Loss: 52.19852\n",
      "Epoch: 23, Loss: 49.77295\n",
      "Epoch: 24, Loss: 47.36170\n",
      "Epoch: 25, Loss: 44.98504\n",
      "Epoch: 26, Loss: 42.66042\n",
      "Epoch: 27, Loss: 40.40241\n",
      "Epoch: 28, Loss: 38.22282\n",
      "Epoch: 29, Loss: 36.13077\n",
      "Epoch: 30, Loss: 34.13284\n",
      "Epoch: 31, Loss: 32.23327\n",
      "Epoch: 32, Loss: 30.43419\n",
      "Epoch: 33, Loss: 28.73590\n",
      "Epoch: 34, Loss: 27.13718\n",
      "Epoch: 35, Loss: 25.63559\n",
      "Epoch: 36, Loss: 24.22777\n",
      "Epoch: 37, Loss: 22.90971\n",
      "Epoch: 38, Loss: 21.67693\n",
      "Epoch: 39, Loss: 20.52474\n",
      "Epoch: 40, Loss: 19.44829\n",
      "Epoch: 41, Loss: 18.44278\n",
      "Epoch: 42, Loss: 17.50347\n",
      "Epoch: 43, Loss: 16.62581\n",
      "Epoch: 44, Loss: 15.80545\n",
      "Epoch: 45, Loss: 15.03830\n",
      "Epoch: 46, Loss: 14.32053\n",
      "Epoch: 47, Loss: 13.64858\n",
      "Epoch: 48, Loss: 13.01919\n",
      "Epoch: 49, Loss: 12.42931\n",
      "Epoch: 50, Loss: 11.87619\n",
      "Embedding dim: 8, Hidden S: 32, Learning Rate: 0.0005\n",
      "Epoch: 1, Loss: 80.39208\n",
      "Epoch: 2, Loss: 80.07097\n",
      "Epoch: 3, Loss: 79.84375\n",
      "Epoch: 4, Loss: 79.61404\n",
      "Epoch: 5, Loss: 79.37883\n",
      "Epoch: 6, Loss: 79.13654\n",
      "Epoch: 7, Loss: 78.88556\n",
      "Epoch: 8, Loss: 78.62422\n",
      "Epoch: 9, Loss: 78.35082\n",
      "Epoch: 10, Loss: 78.06358\n",
      "Epoch: 11, Loss: 77.76070\n",
      "Epoch: 12, Loss: 77.44032\n",
      "Epoch: 13, Loss: 77.10056\n",
      "Epoch: 14, Loss: 76.73953\n",
      "Epoch: 15, Loss: 76.35533\n",
      "Epoch: 16, Loss: 75.94611\n",
      "Epoch: 17, Loss: 75.51005\n",
      "Epoch: 18, Loss: 75.04542\n",
      "Epoch: 19, Loss: 74.55059\n",
      "Epoch: 20, Loss: 74.02406\n",
      "Epoch: 21, Loss: 73.46448\n",
      "Epoch: 22, Loss: 72.87070\n",
      "Epoch: 23, Loss: 72.24179\n",
      "Epoch: 24, Loss: 71.57704\n",
      "Epoch: 25, Loss: 70.87606\n",
      "Epoch: 26, Loss: 70.13872\n",
      "Epoch: 27, Loss: 69.36520\n",
      "Epoch: 28, Loss: 68.55600\n",
      "Epoch: 29, Loss: 67.71191\n",
      "Epoch: 30, Loss: 66.83405\n",
      "Epoch: 31, Loss: 65.92380\n",
      "Epoch: 32, Loss: 64.98280\n",
      "Epoch: 33, Loss: 64.01292\n",
      "Epoch: 34, Loss: 63.01624\n",
      "Epoch: 35, Loss: 61.99498\n",
      "Epoch: 36, Loss: 60.95151\n",
      "Epoch: 37, Loss: 59.88829\n",
      "Epoch: 38, Loss: 58.80785\n",
      "Epoch: 39, Loss: 57.71275\n",
      "Epoch: 40, Loss: 56.60557\n",
      "Epoch: 41, Loss: 55.48885\n",
      "Epoch: 42, Loss: 54.36512\n",
      "Epoch: 43, Loss: 53.23681\n",
      "Epoch: 44, Loss: 52.10631\n",
      "Epoch: 45, Loss: 50.97591\n",
      "Epoch: 46, Loss: 49.84781\n",
      "Epoch: 47, Loss: 48.72408\n",
      "Epoch: 48, Loss: 47.60672\n",
      "Epoch: 49, Loss: 46.49759\n",
      "Epoch: 50, Loss: 45.39843\n",
      "Embedding dim: 8, Hidden S: 64, Learning Rate: 0.001\n",
      "Epoch: 1, Loss: 80.66571\n",
      "Epoch: 2, Loss: 79.72502\n",
      "Epoch: 3, Loss: 79.01389\n",
      "Epoch: 4, Loss: 78.23886\n",
      "Epoch: 5, Loss: 77.35663\n",
      "Epoch: 6, Loss: 76.32811\n",
      "Epoch: 7, Loss: 75.11512\n",
      "Epoch: 8, Loss: 73.68202\n",
      "Epoch: 9, Loss: 71.99856\n",
      "Epoch: 10, Loss: 70.04328\n",
      "Epoch: 11, Loss: 67.80695\n",
      "Epoch: 12, Loss: 65.29505\n",
      "Epoch: 13, Loss: 62.52856\n",
      "Epoch: 14, Loss: 59.54278\n",
      "Epoch: 15, Loss: 56.38426\n",
      "Epoch: 16, Loss: 53.10686\n",
      "Epoch: 17, Loss: 49.76732\n",
      "Epoch: 18, Loss: 46.42110\n",
      "Epoch: 19, Loss: 43.11905\n",
      "Epoch: 20, Loss: 39.90521\n",
      "Epoch: 21, Loss: 36.81568\n",
      "Epoch: 22, Loss: 33.87834\n",
      "Epoch: 23, Loss: 31.11316\n",
      "Epoch: 24, Loss: 28.53284\n",
      "Epoch: 25, Loss: 26.14366\n",
      "Epoch: 26, Loss: 23.94647\n",
      "Epoch: 27, Loss: 21.93764\n",
      "Epoch: 28, Loss: 20.11007\n",
      "Epoch: 29, Loss: 18.45406\n",
      "Epoch: 30, Loss: 16.95815\n",
      "Epoch: 31, Loss: 15.60982\n",
      "Epoch: 32, Loss: 14.39612\n",
      "Epoch: 33, Loss: 13.30424\n",
      "Epoch: 34, Loss: 12.32190\n",
      "Epoch: 35, Loss: 11.43758\n",
      "Epoch: 36, Loss: 10.64074\n",
      "Epoch: 37, Loss: 9.92185\n",
      "Epoch: 38, Loss: 9.27240\n",
      "Epoch: 39, Loss: 8.68483\n",
      "Epoch: 40, Loss: 8.15247\n",
      "Epoch: 41, Loss: 7.66944\n",
      "Epoch: 42, Loss: 7.23057\n",
      "Epoch: 43, Loss: 6.83128\n",
      "Epoch: 44, Loss: 6.46752\n",
      "Epoch: 45, Loss: 6.13570\n",
      "Epoch: 46, Loss: 5.83263\n",
      "Epoch: 47, Loss: 5.55546\n",
      "Epoch: 48, Loss: 5.30164\n",
      "Epoch: 49, Loss: 5.06889\n",
      "Epoch: 50, Loss: 4.85518\n",
      "Embedding dim: 8, Hidden S: 64, Learning Rate: 0.0005\n",
      "Epoch: 1, Loss: 80.92855\n",
      "Epoch: 2, Loss: 80.46522\n",
      "Epoch: 3, Loss: 80.12496\n",
      "Epoch: 4, Loss: 79.77966\n",
      "Epoch: 5, Loss: 79.42210\n",
      "Epoch: 6, Loss: 79.04693\n",
      "Epoch: 7, Loss: 78.64878\n",
      "Epoch: 8, Loss: 78.22216\n",
      "Epoch: 9, Loss: 77.76149\n",
      "Epoch: 10, Loss: 77.26113\n",
      "Epoch: 11, Loss: 76.71549\n",
      "Epoch: 12, Loss: 76.11913\n",
      "Epoch: 13, Loss: 75.46685\n",
      "Epoch: 14, Loss: 74.75388\n",
      "Epoch: 15, Loss: 73.97600\n",
      "Epoch: 16, Loss: 73.12979\n",
      "Epoch: 17, Loss: 72.21271\n",
      "Epoch: 18, Loss: 71.22334\n",
      "Epoch: 19, Loss: 70.16143\n",
      "Epoch: 20, Loss: 69.02802\n",
      "Epoch: 21, Loss: 67.82546\n",
      "Epoch: 22, Loss: 66.55735\n",
      "Epoch: 23, Loss: 65.22845\n",
      "Epoch: 24, Loss: 63.84459\n",
      "Epoch: 25, Loss: 62.41245\n",
      "Epoch: 26, Loss: 60.93938\n",
      "Epoch: 27, Loss: 59.43318\n",
      "Epoch: 28, Loss: 57.90186\n",
      "Epoch: 29, Loss: 56.35344\n",
      "Epoch: 30, Loss: 54.79570\n",
      "Epoch: 31, Loss: 53.23601\n",
      "Epoch: 32, Loss: 51.68120\n",
      "Epoch: 33, Loss: 50.13740\n",
      "Epoch: 34, Loss: 48.61000\n",
      "Epoch: 35, Loss: 47.10364\n",
      "Epoch: 36, Loss: 45.62219\n",
      "Epoch: 37, Loss: 44.16882\n",
      "Epoch: 38, Loss: 42.74608\n",
      "Epoch: 39, Loss: 41.35598\n",
      "Epoch: 40, Loss: 40.00006\n",
      "Epoch: 41, Loss: 38.67947\n",
      "Epoch: 42, Loss: 37.39501\n",
      "Epoch: 43, Loss: 36.14717\n",
      "Epoch: 44, Loss: 34.93620\n",
      "Epoch: 45, Loss: 33.76209\n",
      "Epoch: 46, Loss: 32.62466\n",
      "Epoch: 47, Loss: 31.52354\n",
      "Epoch: 48, Loss: 30.45824\n",
      "Epoch: 49, Loss: 29.42812\n",
      "Epoch: 50, Loss: 28.43250\n",
      "Embedding dim: 16, Hidden S: 32, Learning Rate: 0.001\n",
      "Epoch: 1, Loss: 80.67668\n",
      "Epoch: 2, Loss: 79.75596\n",
      "Epoch: 3, Loss: 79.04644\n",
      "Epoch: 4, Loss: 78.29759\n",
      "Epoch: 5, Loss: 77.48084\n",
      "Epoch: 6, Loss: 76.57273\n",
      "Epoch: 7, Loss: 75.55128\n",
      "Epoch: 8, Loss: 74.39630\n",
      "Epoch: 9, Loss: 73.09030\n",
      "Epoch: 10, Loss: 71.61964\n",
      "Epoch: 11, Loss: 69.97571\n",
      "Epoch: 12, Loss: 68.15583\n",
      "Epoch: 13, Loss: 66.16375\n",
      "Epoch: 14, Loss: 64.00943\n",
      "Epoch: 15, Loss: 61.70856\n",
      "Epoch: 16, Loss: 59.28166\n",
      "Epoch: 17, Loss: 56.75327\n",
      "Epoch: 18, Loss: 54.15090\n",
      "Epoch: 19, Loss: 51.50385\n",
      "Epoch: 20, Loss: 48.84181\n",
      "Epoch: 21, Loss: 46.19319\n",
      "Epoch: 22, Loss: 43.58374\n",
      "Epoch: 23, Loss: 41.03557\n",
      "Epoch: 24, Loss: 38.56680\n",
      "Epoch: 25, Loss: 36.19168\n",
      "Epoch: 26, Loss: 33.92085\n",
      "Epoch: 27, Loss: 31.76173\n",
      "Epoch: 28, Loss: 29.71887\n",
      "Epoch: 29, Loss: 27.79438\n",
      "Epoch: 30, Loss: 25.98833\n",
      "Epoch: 31, Loss: 24.29916\n",
      "Epoch: 32, Loss: 22.72400\n",
      "Epoch: 33, Loss: 21.25900\n",
      "Epoch: 34, Loss: 19.89952\n",
      "Epoch: 35, Loss: 18.64041\n",
      "Epoch: 36, Loss: 17.47618\n",
      "Epoch: 37, Loss: 16.40112\n",
      "Epoch: 38, Loss: 15.40947\n",
      "Epoch: 39, Loss: 14.49547\n",
      "Epoch: 40, Loss: 13.65349\n",
      "Epoch: 41, Loss: 12.87808\n",
      "Epoch: 42, Loss: 12.16400\n",
      "Epoch: 43, Loss: 11.50630\n",
      "Epoch: 44, Loss: 10.90031\n",
      "Epoch: 45, Loss: 10.34167\n",
      "Epoch: 46, Loss: 9.82636\n",
      "Epoch: 47, Loss: 9.35063\n",
      "Epoch: 48, Loss: 8.91107\n",
      "Epoch: 49, Loss: 8.50454\n",
      "Epoch: 50, Loss: 8.12816\n",
      "Embedding dim: 16, Hidden S: 32, Learning Rate: 0.0005\n",
      "Epoch: 1, Loss: 80.79203\n",
      "Epoch: 2, Loss: 80.32289\n",
      "Epoch: 3, Loss: 79.97188\n",
      "Epoch: 4, Loss: 79.61866\n",
      "Epoch: 5, Loss: 79.25875\n",
      "Epoch: 6, Loss: 78.88947\n",
      "Epoch: 7, Loss: 78.50799\n",
      "Epoch: 8, Loss: 78.11142\n",
      "Epoch: 9, Loss: 77.69682\n",
      "Epoch: 10, Loss: 77.26126\n",
      "Epoch: 11, Loss: 76.80183\n",
      "Epoch: 12, Loss: 76.31570\n",
      "Epoch: 13, Loss: 75.80013\n",
      "Epoch: 14, Loss: 75.25252\n",
      "Epoch: 15, Loss: 74.67042\n",
      "Epoch: 16, Loss: 74.05156\n",
      "Epoch: 17, Loss: 73.39392\n",
      "Epoch: 18, Loss: 72.69572\n",
      "Epoch: 19, Loss: 71.95549\n",
      "Epoch: 20, Loss: 71.17210\n",
      "Epoch: 21, Loss: 70.34478\n",
      "Epoch: 22, Loss: 69.47319\n",
      "Epoch: 23, Loss: 68.55744\n",
      "Epoch: 24, Loss: 67.59807\n",
      "Epoch: 25, Loss: 66.59612\n",
      "Epoch: 26, Loss: 65.55310\n",
      "Epoch: 27, Loss: 64.47096\n",
      "Epoch: 28, Loss: 63.35211\n",
      "Epoch: 29, Loss: 62.19931\n",
      "Epoch: 30, Loss: 61.01570\n",
      "Epoch: 31, Loss: 59.80469\n",
      "Epoch: 32, Loss: 58.56992\n",
      "Epoch: 33, Loss: 57.31516\n",
      "Epoch: 34, Loss: 56.04430\n",
      "Epoch: 35, Loss: 54.76121\n",
      "Epoch: 36, Loss: 53.46975\n",
      "Epoch: 37, Loss: 52.17363\n",
      "Epoch: 38, Loss: 50.87644\n",
      "Epoch: 39, Loss: 49.58156\n",
      "Epoch: 40, Loss: 48.29215\n",
      "Epoch: 41, Loss: 47.01112\n",
      "Epoch: 42, Loss: 45.74111\n",
      "Epoch: 43, Loss: 44.48451\n",
      "Epoch: 44, Loss: 43.24346\n",
      "Epoch: 45, Loss: 42.01985\n",
      "Epoch: 46, Loss: 40.81534\n",
      "Epoch: 47, Loss: 39.63136\n",
      "Epoch: 48, Loss: 38.46913\n",
      "Epoch: 49, Loss: 37.32968\n",
      "Epoch: 50, Loss: 36.21386\n",
      "Embedding dim: 16, Hidden S: 64, Learning Rate: 0.001\n",
      "Epoch: 1, Loss: 80.68536\n",
      "Epoch: 2, Loss: 79.40384\n",
      "Epoch: 3, Loss: 78.38262\n",
      "Epoch: 4, Loss: 77.26442\n",
      "Epoch: 5, Loss: 75.98332\n",
      "Epoch: 6, Loss: 74.48078\n",
      "Epoch: 7, Loss: 72.70217\n",
      "Epoch: 8, Loss: 70.60044\n",
      "Epoch: 9, Loss: 68.14217\n",
      "Epoch: 10, Loss: 65.31407\n",
      "Epoch: 11, Loss: 62.12759\n",
      "Epoch: 12, Loss: 58.62020\n",
      "Epoch: 13, Loss: 54.85269\n",
      "Epoch: 14, Loss: 50.90367\n",
      "Epoch: 15, Loss: 46.86189\n",
      "Epoch: 16, Loss: 42.81759\n",
      "Epoch: 17, Loss: 38.85468\n",
      "Epoch: 18, Loss: 35.04515\n",
      "Epoch: 19, Loss: 31.44627\n",
      "Epoch: 20, Loss: 28.09986\n",
      "Epoch: 21, Loss: 25.03279\n",
      "Epoch: 22, Loss: 22.25832\n",
      "Epoch: 23, Loss: 19.77777\n",
      "Epoch: 24, Loss: 17.58265\n",
      "Epoch: 25, Loss: 15.65696\n",
      "Epoch: 26, Loss: 13.97961\n",
      "Epoch: 27, Loss: 12.52653\n",
      "Epoch: 28, Loss: 11.27250\n",
      "Epoch: 29, Loss: 10.19256\n",
      "Epoch: 30, Loss: 9.26303\n",
      "Epoch: 31, Loss: 8.46229\n",
      "Epoch: 32, Loss: 7.77107\n",
      "Epoch: 33, Loss: 7.17263\n",
      "Epoch: 34, Loss: 6.65266\n",
      "Epoch: 35, Loss: 6.19906\n",
      "Epoch: 36, Loss: 5.80168\n",
      "Epoch: 37, Loss: 5.45203\n",
      "Epoch: 38, Loss: 5.14305\n",
      "Epoch: 39, Loss: 4.86886\n",
      "Epoch: 40, Loss: 4.62453\n",
      "Epoch: 41, Loss: 4.40594\n",
      "Epoch: 42, Loss: 4.20964\n",
      "Epoch: 43, Loss: 4.03272\n",
      "Epoch: 44, Loss: 3.87271\n",
      "Epoch: 45, Loss: 3.72752\n",
      "Epoch: 46, Loss: 3.59537\n",
      "Epoch: 47, Loss: 3.47473\n",
      "Epoch: 48, Loss: 3.36429\n",
      "Epoch: 49, Loss: 3.26292\n",
      "Epoch: 50, Loss: 3.16963\n",
      "Embedding dim: 16, Hidden S: 64, Learning Rate: 0.0005\n",
      "Epoch: 1, Loss: 80.54128\n",
      "Epoch: 2, Loss: 79.84687\n",
      "Epoch: 3, Loss: 79.30832\n",
      "Epoch: 4, Loss: 78.75513\n",
      "Epoch: 5, Loss: 78.17743\n",
      "Epoch: 6, Loss: 77.56782\n",
      "Epoch: 7, Loss: 76.91871\n",
      "Epoch: 8, Loss: 76.22243\n",
      "Epoch: 9, Loss: 75.47142\n",
      "Epoch: 10, Loss: 74.65831\n",
      "Epoch: 11, Loss: 73.77608\n",
      "Epoch: 12, Loss: 72.81815\n",
      "Epoch: 13, Loss: 71.77862\n",
      "Epoch: 14, Loss: 70.65244\n",
      "Epoch: 15, Loss: 69.43567\n",
      "Epoch: 16, Loss: 68.12573\n",
      "Epoch: 17, Loss: 66.72160\n",
      "Epoch: 18, Loss: 65.22408\n",
      "Epoch: 19, Loss: 63.63587\n",
      "Epoch: 20, Loss: 61.96166\n",
      "Epoch: 21, Loss: 60.20807\n",
      "Epoch: 22, Loss: 58.38352\n",
      "Epoch: 23, Loss: 56.49799\n",
      "Epoch: 24, Loss: 54.56270\n",
      "Epoch: 25, Loss: 52.58970\n",
      "Epoch: 26, Loss: 50.59150\n",
      "Epoch: 27, Loss: 48.58066\n",
      "Epoch: 28, Loss: 46.56940\n",
      "Epoch: 29, Loss: 44.56933\n",
      "Epoch: 30, Loss: 42.59116\n",
      "Epoch: 31, Loss: 40.64455\n",
      "Epoch: 32, Loss: 38.73800\n",
      "Epoch: 33, Loss: 36.87877\n",
      "Epoch: 34, Loss: 35.07294\n",
      "Epoch: 35, Loss: 33.32538\n",
      "Epoch: 36, Loss: 31.63989\n",
      "Epoch: 37, Loss: 30.01922\n",
      "Epoch: 38, Loss: 28.46523\n",
      "Epoch: 39, Loss: 26.97895\n",
      "Epoch: 40, Loss: 25.56072\n",
      "Epoch: 41, Loss: 24.21030\n",
      "Epoch: 42, Loss: 22.92697\n",
      "Epoch: 43, Loss: 21.70962\n",
      "Epoch: 44, Loss: 20.55683\n",
      "Epoch: 45, Loss: 19.46695\n",
      "Epoch: 46, Loss: 18.43811\n",
      "Epoch: 47, Loss: 17.46830\n",
      "Epoch: 48, Loss: 16.55536\n",
      "Epoch: 49, Loss: 15.69705\n",
      "Epoch: 50, Loss: 14.89103\n",
      "{'embedding dim': 16, 'hidden_size': 64, 'learning_rt': 0.001}\n",
      "3.1696342937648296\n"
     ]
    }
   ],
   "source": [
    "embedding_sizes = [8, 16]\n",
    "hidden_size = [32, 64]\n",
    "learning_rates = [0.001, 0.0005]\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "best_params = {}\n",
    "\n",
    "print(\"Hyperparameter tuning basliyor\")\n",
    "\n",
    "for emb_size, hidden_s, lr in product(embedding_sizes, hidden_size, learning_rates):\n",
    "    print(f\"Embedding dim: {emb_size}, Hidden S: {hidden_s}, Learning Rate: {lr}\")\n",
    "\n",
    "    model = LSTM(vocab_size=len(vocab), embedding_dim=emb_size, hidden_size=hidden_s)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "    epochs = 50\n",
    "    total_loss = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for word, next_word in data:\n",
    "\n",
    "            model.zero_grad()\n",
    "            input_tensor = prepare_squence([word], word_to_index)\n",
    "            target_tensor = prepare_squence([next_word], word_to_index)\n",
    "            output = model(input_tensor)\n",
    "            loss = loss_fn(output, target_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        if epochs % 10 == 0:\n",
    "            print(f\"Epoch: {epoch+1}, Loss: {epoch_loss:.5f}\")\n",
    "        \n",
    "        total_loss = epoch_loss\n",
    "\n",
    "    if total_loss < best_loss:\n",
    "        best_loss = total_loss\n",
    "        best_params = {\"embedding dim\": emb_size, \"hidden_size\": hidden_s, \"learning_rt\":lr}\n",
    "\n",
    "print(best_params)\n",
    "print(best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5bf08a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model training...\n",
      "Final model epoch: 0, loss: 80.70260\n",
      "Final model epoch: 10, loss: 61.76485\n",
      "Final model epoch: 20, loss: 23.96613\n",
      "Final model epoch: 30, loss: 7.86713\n",
      "Final model epoch: 40, loss: 4.13841\n",
      "Final model epoch: 50, loss: 2.92710\n",
      "Final model epoch: 60, loss: 2.38864\n",
      "Final model epoch: 70, loss: 2.10072\n",
      "Final model epoch: 80, loss: 1.92783\n",
      "Final model epoch: 90, loss: 1.81548\n"
     ]
    }
   ],
   "source": [
    "final_model = LSTM(vocab_size=len(vocab), embedding_dim=16, hidden_size=64)\n",
    "optimizer = optim.Adam(params=final_model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Final model training...\")\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for word, next_word in data:\n",
    "\n",
    "        final_model.zero_grad()\n",
    "        input_tensor = prepare_squence([word], word_to_index)\n",
    "        target_tensor = prepare_squence([next_word], word_to_index)\n",
    "        output = final_model(input_tensor)\n",
    "        loss = loss_fn(output, target_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Final model epoch: {epoch}, loss: {epoch_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afb5e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_squence(start_word, num_of_word):\n",
    "    current_word = start_word\n",
    "    output_squence = [current_word]\n",
    "\n",
    "    for _ in range(num_of_word):\n",
    "        with torch.no_grad():\n",
    "            input_tensor = prepare_squence([current_word], word_to_index)\n",
    "            output = final_model(input_tensor)\n",
    "            predicted_idx = torch.argmax(output).item()\n",
    "            predicted_word = index_to_vocab[predicted_idx]\n",
    "            output_squence.append(predicted_word)\n",
    "\n",
    "            current_word = predicted_word\n",
    "\n",
    "    return output_squence\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3240004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_word = \"ürün\"\n",
    "num_of_word = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6b6405fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(num_of_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54f5ddb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ürün', 'beklentimi']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_sequence = predict_squence(start_word, num_of_word)\n",
    "predicted_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040cd8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
